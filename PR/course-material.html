<!DOCTYPE html>
<html lang="en">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- <meta http-equiv="X-UA-Compatible" content="IE=edge"> -->
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <title>CSE 812T: Pattern Recognition</title>

  <!-- bootstrap -->
  <!-- <link rel="stylesheet" href="./style/bootstrap.min.css"> -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap-theme.min.css" integrity="sha384-rHyoN1iRsVXV4nD0JutlnGaslCJuC7uwjduW9SVrLvRYooPp2bWYgmgJQIXwl/Sp" crossorigin="anonymous">
  <!--<link rel="stylesheet" href="./style/bootstrap-theme.min.css">-->
  <link href="./style/newstyle.css" rel="stylesheet" type="text/css">
  
  <body>
  <nav class="navbar navbar-expand-md navbar-light navbar-fixed-top">
    <a href="#">
      <img src="./images/iust-logo2.png" style="height:60px; float: left; margin-left: 20px; margin-right: 20px;"></a>
      <a class="navbar-brand" href="#">CSE 812T - Pattern Recognition</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarsExampleDefault">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item"><a class="nav-link" href="course-site.html">Main Page</a></li>
		<li class="nav-item"><a class="nav-link" href="#schedule">Lecture Plan</a></li>
        <li class="nav-item"><a class="nav-link" href="#opt">Supplementary Materials</a></li>
        <li class="nav-item"><a class="nav-link" href="#">Moodle</a></li>
      </ul>
    </div>
  </nav>
  <br/>

<div class="sechighlight">
<div class="container sec" style="margin-top: 1em">
  <h2>Course Materials and schedule</h2>
  <p>
  <b>Time and Location</b>:
  To be announced soon.
  
<br>
</div>
</div>


<div class="container">
<table id="schedule" class="table table-bordered no-more-tables">
  <thead class="active" style="background-color:magenta">
    <th>Event</th><th>Date</th><th>Description</th><th>Materials and Assignments</th>
  </thead>

  <tbody>
  <tr>
    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:cyan">
      <strong>Review of Maths Topics necessary for Pattern Recognition</strong> (3 classes)
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;1</td>
    <td> TBD </td>
    <td>
      1. Probability Distributions and Densities.
    </td>
    <td>

    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;2</td>
    <td> TBD </td>
    <td>
      2. Linear Algebra Review
    </td>
    <td>

    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;3</td>
    <td> TBD </td>
    <td>
      3. Optimization Basics.
    </td>
    <td>

    </td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>Practice Problems</td>
	<td></td>
  </tr>
  <tr><td colspan="4"></td></tr>
  <tr>
    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:cyan">
      <strong>Generative classifiers; Density Estimation</strong> (7 classes)
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;4</td>
    <td>TBD</td>
    <td>1. Bayes' Decision Theory; Decision Boundaries and surfaces; Parametric Models.
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;5</td>
    <td> TBD </td>
    <td>
      2. Minimum Error Classifier; Minimum Risk Decision Rule
    </td>
    <td>

    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;6</td>
    <td> TBD </td>
    <td>
      3. Maximum Likelihood Estimate (Univariate and multivariate Gaussian)
    </td>
  </tr>
	<tr>
    <td>Lecture&nbsp;7</td>
    <td> TBD </td>
    <td>
      4. Maximum A-priori Estimate (Univariate and Multivariate Gaussian)
    </td>
    <td>

    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;8</td>
    <td> TBD </td>
    <td>
      6. Multimodal Distributions; k-means algorithm
    </td>
	</tr>
	 <tr>
    <td>Lecture&nbsp;9</td>
    <td> TBD </td>
    <td>
      7. Gaussian Mixture Models; EM Algorithm; MLE Estimation
    </td>
    <td>

    </td>
  </tr>

  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Assignment 1</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  <tr><td colspan="4"></td></tr>
    <tr style="background-color:orange">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Project Proposals</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  <tr><td colspan="4"></td></tr>
  <tr>
    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:cyan">
      <strong>Non-parametric Density Estimation</strong> (2 classes)
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;10</td>
    <td>TBD</td>
    <td>1. Introduction to Non-parametric Density Estimation
    </td>
	</tr>
<tr>
    <td>Lecture&nbsp;11</td>
    <td>TBD</td>
    <td>2. Parzen window and Nearest Neighbour Estimation; kNN Classifier.
    </td>
    <td>
    </td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>Practice Problems</td>
	<td></td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Assignment 2</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  <tr><td colspan="4"></td></tr>
  <tr style="background-color:orange">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Midsem</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  <tr><td colspan="4"></td></tr>
<tr>
    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:cyan">
      <strong>Discriminative Models</strong> (7 classes)
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;12</td>
    <td>TBD</td>
    <td>1. Logistic Regression
    </td>
	</tr>
	<tr>
    <td>Lecture&nbsp;13</td>
    <td>TBD</td>
    <td>2. Perceptron Model; Introduction to the concept of Margins
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;14</td>
    <td>TBD</td>
    <td>3. Support Vector Machines - Problem Formulation
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;15</td>
    <td>TBD</td>
    <td>4. Support Vector Machines - Soft Margins; Kernel Trick
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;16</td>
    <td>TBD</td>
    <td>5. Review of Logistic Regression; Introduction to the Idea of Back Propagation
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;17</td>
    <td>TBD</td>
    <td>6. Neural Networks - Forward Propagation
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;18</td>
    <td>TBD</td>
    <td>7. Backpropagation
    </td>
    <td>
    </td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>Practice Problems</td>
	<td></td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Assignment 3</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  <tr><td colspan="4"></td></tr>
  
  <tr>
    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:cyan">
      <strong>Dimensionality Reduction</strong> (7 classes)
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;19</td>
    <td>TBD</td>
    <td>1. Curse of Dimensionality; Introduction to PCA
    </td>
	</tr>
	<tr>
    <td>Lecture&nbsp;20</td>
    <td>TBD</td>
    <td>2. PCA; Singular Value Decomposition 
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture&nbsp;21</td>
    <td>TBD</td>
    <td>3. Linear Discriminant Analysis
    </td>
    <td>
    </td>
  </tr>
  
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>Practice Problems</td>
	<td></td>
  </tr>
  <tr style="background-color:yellow">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Assignment 4</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
    <tr><td colspan="4"></td></tr>
  <tr style="background-color:orange">
    <td>Homework</td>
    <td>TBD</td>
    <td>
      <strong>Project Submission</strong></td>
	<td> <a href="#">Instructions</a>. <br>
    </td>
  </tr>
  
  <tr><td colspan="4"></td></tr>
  <tr class="warning" id="opt">
    <td colspan="4">
    <b>Supplementary Notes</b>
    <ol>
      <li>Binary classification with +/-1 labels [<a href="http://cs229.stanford.edu/extra-notes/loss-functions.pdf">pdf</a>]</li>
      <li>Boosting algorithms and weak learning [<a href="http://cs229.stanford.edu/extra-notes/boosting.pdf">pdf</a>] </li>
      <li>Functional after implementing stump_booster.m in PS2. [<a href="http://cs229.stanford.edu/extra-notes/boosting_example.m">here</a>] </li>
      <li>The representer theorem [<a href="http://cs229.stanford.edu/extra-notes/representer-function.pdf">pdf</a>]</li>
      <li>Hoeffding's inequality [<a href="http://cs229.stanford.edu/extra-notes/hoeffding.pdf">pdf</a>] </li>
    </ol></td>
  </tr>

  <tr class="alert">
    <td colspan="4">
    <b>Section Notes</b>
    <ol>
      <li id="la">Linear Algebra Review and Reference [<a href="http://cs229.stanford.edu/section/cs229-linalg.pdf">pdf</a>]</li>
      <li>Probability Theory Review [<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">pdf</a>] </li>
      
      <li>Convex Optimization Overview, Part I [<a href="http://cs229.stanford.edu/section/cs229-cvxopt.ps">ps</a>] [<a href="http://cs229.stanford.edu/section/cs229-cvxopt.pdf">pdf</a>]</li>
      <li>Convex Optimization Overview, Part II [<a href="http://cs229.stanford.edu/section/cs229-cvxopt2.ps">ps</a>] [<a href="http://cs229.stanford.edu/section/cs229-cvxopt2.pdf">pdf</a>] </li>

      <li>The Multivariate Gaussian Distribution [<a href="http://cs229.stanford.edu/section/gaussians.pdf">pdf</a>] </li>
      <li>More on Gaussian Distribution [<a href="http://cs229.stanford.edu/section/more_on_gaussians.pdf">pdf</a>] </li>
      <li>Gaussian Processes [<a href="http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf">pdf</a>] </li>
    </ol></td>
  </tr>
  <tr>
    <td colspan="4">
      <b>Other Resources</b>
      <ol>
        <li>Advice on applying machine learning: Slides from Andrew's lecture on getting machine learning algorithms to work in practice can be found <a href="http://cs229.stanford.edu/materials/ML-advice.pdf">here</a>.<br></li>
        
        <li>Matlab resources: Here are a couple of Matlab tutorials that you might find helpful: <a href="http://www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html">http://www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html</a> and <a href="http://www.math.mtu.edu/~msgocken/intro/node1.html">http://www.math.mtu.edu/~msgocken/intro/node1.html</a>. For emacs users only: If you plan to run Matlab in emacs, here are <a href="http://cs229.stanford.edu/materials/matlab.el">matlab.el</a>, and a helpful <a href="http://cs229.stanford.edu/materials/emacs">.emac's</a> file.<br></li>
        <li>Octave resources: For a free alternative to Matlab, check out <a href="http://www.gnu.org/software/octave/">GNU Octave</a>. The official documentation is available <a href="http://www.gnu.org/software/octave/doc/interpreter/">here</a>. Some useful tutorials on Octave include <a href="http://en.wikibooks.org/wiki/Octave_Programming_Tutorial">http://en.wikibooks.org/wiki/Octave_Programming_Tutorial</a> and <a href="http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf">http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf</a> .<br></li>
        <li>Data: Here is the <a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">UCI Machine learning repository</a>, which contains a large collection of standard datasets for testing learning algorithms. If you want to see examples of recent work in machine learning, start by taking a look at the conferences <a href="http://www.nips.cc/">NIPS</a>(all old NIPS papers are online) and ICML. Some other related conferences include UAI, AAAI, IJCAI.<br></li>
        <li>Viewing PostScript and PDF files: Depending on the computer you are using, you may be able to download a <a href="http://www.cs.wisc.edu/~ghost/">PostScript</a> viewer or <a href="http://www.adobe.com/products/acrobat/readstep2_allversions.html">PDF viewer</a> for it if you don't already have one.<br></li>
      </ol>
    </td>
  </tr>

</tbody></table>
</div>

</body></html>
